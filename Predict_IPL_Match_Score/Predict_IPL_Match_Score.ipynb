{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"IPL_Logo.png\" width=\"240\" height=\"360\" />\n",
    "\n",
    "## Exploratory Data Analysis of Indian Premier League Matches and Predicting Match Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Problem Statement](#section1)<br>\n",
    "2. [Data Loading and Description](#section2)\n",
    "3. [Data Profiling](#section3)\n",
    "    - 3.1 [Understanding the Dataset](#section301)<br/>\n",
    "    - 3.2 [Pre Profiling](#section302)<br/>\n",
    "    - 3.3 [Preprocessing](#section303)<br/>\n",
    "    - 3.4 [Post Profiling](#section304)<br/>\n",
    "4. [Questions](#section4)\n",
    "    - 4.1 [How many feature play a key role in deciding what the final score?](#section401)<br/>\n",
    "    - 4.2 [What type of correlation between features to predict match score](#section402)<br/>\n",
    "5. [Preparing X (independent features) for the model building.](#section5)\n",
    "    - 5.1 [Check for the type and shape of X.](#section501)<br/>\n",
    "6. [Extract y (dependent variable) for model building.](#section5)\n",
    "    - 6.1 [Check for the type and shape of y.](#section601)<br/>\n",
    "7. [Split the value of X and y into train and test datasets](#section7)\n",
    "8. [Features Scaling](#section8)\n",
    "9. [Check the shape of X and y of train dataset.](#section9)\n",
    "10. [Check the shape of X and y of test dataset.](#section10)\n",
    "11. [Instantiate Linear regression model using scikit-learn.](#section11)\n",
    "12. [Fit the linear model on X_train and y_train.](#section12)\n",
    "13. [Interpret the Model Coefficients.](#section13)\n",
    "14. [Zip the features to pair the feature names with the coefficients.](#section14)\n",
    "15. [Predict the train value using the built model.](#section15)\n",
    "16. [Predict the test value using the built model.](#section16)\n",
    "17. [Evaluate the model](#section17)\n",
    "    - 17.1 [Using Mean Absolute Error metrics for both train and test.](#section1701)<br/>\n",
    "    - 17.2 [Using Mean Squared Error for both train and test.](#section1702)<br/>\n",
    "    - 17.3 [Using Root Mean Squared Error for both train and test.](#section1703)<br/>\n",
    "    - 17.4 [Using R-square value for both train and test.](#section1704)<br/>    \n",
    "18. [Conclusions](#section18)<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ODI and T-20 cricket, many factors play a key role in deciding what the final score will be.  Let’s look at some of the key factors:\n",
    "\n",
    "- Number of wickets left\n",
    "- Number of balls left\n",
    "- On how much scores are the current batsman batting?\n",
    "- How much the team had scored in last 5 overs?\n",
    "- How much the team had lost wickets in last 5 overs?\n",
    "- The nature of the pitch\n",
    "- How strong is the batting and bowling team?\n",
    "\n",
    "Let's use some of these factors __to predict match score using machine learning algorithms based on past data, Visualizations, Perspectives, etc__. \n",
    "We use regression analysis in machine learning to predict the final score of an ODI or T-20 match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Loading and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used ‘ipl.csv’ datafile here for predicting scores in IPL cricket match. \n",
    "The dataset contains ball by ball coverage of:\n",
    "\n",
    "- 1188 ODI matches: data/odi.csv\n",
    "- 1474 T-20 matches: data/t20.csv\n",
    "- 617 IPL matches: data/ipl.csv\n",
    "\n",
    "The dataset contains details information related to matches,the ball by ball details of matches, such as venue, bat_team bowl_team, runs, wickets, overs etc.\n",
    "- The dataset comprises of __76014 observations of 15 columns__. Below is a table showing names of all the columns and their description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column Name        | Description                                             |\n",
    "| ------------------ |:-------------                                          :| \n",
    "| mid                | Identity of match                                             | \n",
    "| date               | When the match happened                                       |  \n",
    "| venue              | Stadium where match is being played                           | \n",
    "| bat_team           | Batting team name                                             |   \n",
    "| bowl_team          | Bowling team name                                             |\n",
    "| batsman            | Batsman name who faced that ball                              |\n",
    "| bowler             | Bowler who bowled that ball                                   |\n",
    "| runs               | Total runs scored by team at that instance                    | \n",
    "| wickets            | Total wickets fallen at that instance                         |\n",
    "| overs              | Total overs bowled at that instance                           |\n",
    "| runs_last_5        | Total runs scored in last 5 overs                             |\n",
    "| wickets_last_5     | Total wickets that fell in last 5 overs                       |\n",
    "| striker            | max(runs scored by striker, runs scored by non-striker)       |\n",
    "| non-striker        | min(runs scored by striker, runs scored by non-striker)       |\n",
    "| total              | Total runs scored by batting team after first innings         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source :\n",
    "https://cricsheet.org/downloads/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                 # Implemennts milti-dimensional array and matrices\n",
    "import pandas as pd                                                # For data manipulation and analysis\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt                                    # Plotting library for Python programming language and it's numerical mathematics extension NumPy\n",
    "import seaborn as sns                                              # Provides a high level interface for drawing attractive and informative statistical graphics\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "from subprocess import check_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data = pd.read_csv(\"data/ipl.csv\")     # Importing training dataset using pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the upcoming sections we will first __understand our dataset__ using various pandas functionalities.\n",
    "- Then with the help of __pandas profiling__ we will find which columns of our dataset need preprocessing.\n",
    "- In __preprocessing__ we will deal with erronous and missing values of columns. \n",
    "- Again we will do __pandas profiling__ to see how preprocessing have transformed our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section301></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Understanding the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain insights from data we must look into each aspect of it very carefully. We will start with observing few rows and columns of data both from the starting and from the end.\n",
    "\n",
    "Let us check the basic information of the dataset. The very basic information to know is the dimension of the dataset – rows and columns – that’s what we find out with the method __shape__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matches_data has __76014 rows and 15 columns.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section302></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pre Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By pandas profiling, an __interactive HTML report__ gets generated which contins all the information about the columns of the dataset, like the __counts and type__ of each _column_. Detailed information about each column, __correlation between different columns__ and a sample of dataset.<br/>\n",
    "- It gives us __visual interpretation__ of each column in the data.\n",
    "- _Spread of the data_ can be better understood by the distribution plot. \n",
    "- _Grannular level_ analysis of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pandas_profiling.ProfileReport(matches_data)\n",
    "profile.to_file(outputfile=\"matches_data_before_preprocessing.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have done Pandas Profiling before preprocessing our dataset, so we have named the html file as __matches_data_before_preprocessing.html__. Take a look at the file and see what useful insight you can develop from it. <br/>\n",
    "Now we will process our data to better understand it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section303></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dealing with missing values<br/>\n",
    "    - Replacing incorrect & multiple entry of the Pune team from bat_team column and bowl_team.\n",
    "    - Value in overs column should be less than 20 overs means 19.6\n",
    "    - Since data set contains details information about match ball by ball for second inning, check chasing runs score in runs column should be relative with total runs.\n",
    "    - Value in wickets & wickets_last_5 column should less than or equal to 10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_names = ['rising pune supergiant', 'pune warriors']\n",
    "pune_team_name = 'Rising Pune Supergiants'\n",
    "\n",
    "for (row, col) in matches_data.iterrows():\n",
    "     \n",
    "    if str.lower(col.bat_team) in incorrect_names:\n",
    "        matches_data['bat_team'].replace(to_replace=col.bat_team, value=pune_team_name, inplace=True)\n",
    "    \n",
    "    if str.lower(col.bowl_team) in incorrect_names:\n",
    "        matches_data['bowl_team'].replace(to_replace=col.bowl_team, value=pune_team_name, inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.overs.sort_values(ascending=False).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.total.sort_values(ascending=False).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.runs.sort_values(ascending=False).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.wickets_last_5.sort_values(ascending=False).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.wickets.sort_values(ascending=False).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section304></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Post Pandas Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas_profiling\n",
    "profile = pandas_profiling.ProfileReport(matches_data)\n",
    "profile.to_file(outputfile=\"matches_data_after_preprocessing.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have preprocessed the data, now the dataset doesnot contain missing values. You can compare the two reports, i.e __matches_data_after_preprocessing.html__ and __matches_data_before_preprocessing.html__.<br/>\n",
    "In __matches_data__after_preprocessing.html__ report, observations:\n",
    "- In the Dataset info, Total __Missing(%)__ = __0.0%__ \n",
    "- Number of __variables__ = __13__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section304></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Utils functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChartType:\n",
    "    bar_chart = 1\n",
    "    bar_chart_horizontal = 2\n",
    "    line_chart = 3\n",
    "    histogram_chart = 4\n",
    "    stack_chart = 5\n",
    "    scatter_chart = 6\n",
    "    area_chart = 7\n",
    "    pie_chart = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showChart(data, chart_type, xlabel, ylabel, title=None, figsize=None, axis=None):\n",
    "    '''\n",
    "    data : data frame,\n",
    "    xlabel : The label text for x axis.\n",
    "    ylabel : The label text for y axis.\n",
    "    title : The label text for title of chart.\n",
    "    figsize : tuple of integers, optional, default: None\n",
    "    axis : The axis limits to be set. Either none or all of the limits must\n",
    "    be given.\n",
    "    '''\n",
    "    # Set figure size of chart\n",
    "    if figsize != None:\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "    # Set x & y axis limit\n",
    "    if axis != None:\n",
    "        plt.axis(axis) \n",
    "\n",
    "    # Draw bar chart\n",
    "    if ChartType.bar_chart == chart_type:\n",
    "        data.plot.bar()\n",
    "    elif ChartType.bar_chart_horizontal == chart_type:\n",
    "        data.plot.barh()\n",
    "    elif ChartType.stack_chart == chart_type:\n",
    "        data.plot.bar(stacked=True)\n",
    "    elif ChartType.line_chart == chart_type:\n",
    "        data.plot.line()\n",
    "    elif ChartType.histogram_chart == chart_type:\n",
    "        data.plot.hist()\n",
    "    elif ChartType.scatter_chart == chart_type:\n",
    "        data.plot.area()\n",
    "    elif ChartType.area_chart == chart_type:\n",
    "        data.plot.area()\n",
    "    elif ChartType.pie_chart == chart_type:\n",
    "        plt.pie(data.values,\n",
    "                       labels=data.index,\n",
    "                       autopct='%1.2f', startangle=90)\n",
    "        \n",
    "#         explode = (0.2, 0, 0, 0, 0, 0)\n",
    "#         plt.explode = explode\n",
    "#         plt.autopct='%1.1f%%'\n",
    "        plt.legend(data.index, loc=\"best\")\n",
    "        plt.axis('equal')\n",
    "#         plt.pctdistance=1.1\n",
    "#         plt.labeldistance=1.2\n",
    "#         data.plot.pie()\n",
    "        \n",
    "    # Set title of chart, y & x axis\n",
    "    if title != None:\n",
    "        plt.title(title, fontsize=20)\n",
    "        \n",
    "    if xlabel != None:\n",
    "        plt.xlabel(xlabel, fontsize=10)\n",
    "\n",
    "    if ylabel != None:\n",
    "        plt.ylabel(ylabel, fontsize=10)\n",
    "\n",
    "    # Custom ticks for m axis\n",
    "    plt.tick_params(axis='x', colors='black', direction='out', length=5, width=1, labelsize='large')\n",
    "    \n",
    "    # Custom ticks for m axis\n",
    "    plt.tick_params(axis='y', colors='black', direction='in', length=5, width=1, labelsize='large')\n",
    "    \n",
    "    # Show char\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section401></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4.1 How many feature play a key role in deciding what the final score?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = matches_data.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr,vmax=.8,linewidth=.01, square = True, annot = True,cmap='YlGnBu',linecolor ='black')\n",
    "plt.title('Correlation between features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to do same analysis using seaborn lib without filter data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section401></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4.2 What type of correlation between features to predict match score?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(matches_data, x_vars=[\"overs\", \"wickets\", \"striker\", \"non-striker\"], y_vars=[\"runs\"], height=5, aspect=.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By referring above graph, we can clearly say that, there is liner relationship between overs and runs feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section5></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparing X (independent features) for the model building. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section501></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ODI and T-20 cricket, many factors play a key role in deciding what the final score will be.  Let’s look at some of the key factors:\n",
    "\n",
    "- Number of wickets left\n",
    "- Number of balls left\n",
    "- On how much scores are the current batsman batting?\n",
    "- How much the team had scored in last 5 overs?\n",
    "- How much the team had lost wickets in last 5 overs?\n",
    "- The nature of the pitch\n",
    "- How strong is the batting and bowling team?\n",
    "\n",
    "While preprocessing, we can clearly say all other features didn’t make much difference in results, except below mentioned variables which has corelationshiop & will help in prediction of match score:\n",
    "- runs\n",
    "- wickets\n",
    "- overs\n",
    "- striker\n",
    "- non-striker\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate way to fetch data from data set\n",
    "#X = matches_data.iloc[:,[7,8,9,12,13]].values\n",
    "\n",
    "# define column which want to filter\n",
    "feature_cols = ['runs','wickets','overs','striker','non-striker']                \n",
    "def extract_X_Independent(matches_data):\n",
    "    X = matches_data[feature_cols]\n",
    "    return X\n",
    "\n",
    "# Prepare X data set\n",
    "X = extract_X_Independent(matches_data)\n",
    "\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section501></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Check for the type and shape of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr():\n",
    "    print(type(X))\n",
    "    print(X.shape)\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section6></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Extract y (dependent variable) for model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate way to fetch data from data set\n",
    "# y = matches_data.iloc[:, 14].values\n",
    "\n",
    "# define column which want to predict\n",
    "def extract_y_Dependent(data_set):\n",
    "    y = data_set['total']\n",
    "    return y\n",
    "\n",
    "# Prepare y data set\n",
    "y = extract_y_Dependent(matches_data)\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section601></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Check for the type and shape of y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr():\n",
    "    print(type(y))\n",
    "    print(y.shape)\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section7></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Split the value of X and y into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_X_y_Into_Train_Test():\n",
    "    return train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "X_train, X_test, y_train, y_test = split_X_y_Into_Train_Test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section8></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section9></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Check the shape of X and y of train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr():\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section10></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Check the shape of X and y of test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr():\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section11></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Instantiate Linear regression model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def lr():\n",
    "    linreg = LinearRegression()\n",
    "    return linreg\n",
    "linreg = lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def lr():\n",
    "    linreg = RandomForestRegressor(n_estimators=100,max_features=None)\n",
    "    return linreg\n",
    "linreg = lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section12></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Fit the linear model on X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr():\n",
    "    linreg.fit(X_train, y_train)  \n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section13></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Interpret the Model Coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr():\n",
    "    print('Intercept:',linreg.intercept_)                                            \n",
    "    print('Coefficients:',linreg.coef_)\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section14></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Zip the features to pair the feature names with the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr():\n",
    "    feature_cols.insert(0,'Intercept')\n",
    "    coef = linreg.coef_.tolist()\n",
    "    coef.insert(0, linreg.intercept_)\n",
    "    eq1 = zip(feature_cols, coef)\n",
    "    for c1,c2 in eq1:\n",
    "        print(c1,c2)\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section15></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Predict the train value using the built model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = linreg.predict(X_train)\n",
    "pred= pd.DataFrame(y_pred_train)\n",
    "def lr():  \n",
    "    pred.columns = ['total']\n",
    "    head = pred.head()\n",
    "    return head\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section16></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Predict the test value using the built model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = linreg.predict(X_test)    \n",
    "pred_test= pd.DataFrame(y_pred_test)\n",
    "def lr():\n",
    "    pred_test.columns=['total']\n",
    "    head = pred_test.head()\n",
    "    return head\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section17></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1701></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.1 Using Mean Absolute Error metrics for both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def lr():\n",
    "    MAE_train = metrics.mean_absolute_error(y_train, y_pred_train)\n",
    "    MAE_test = metrics.mean_absolute_error(y_test, y_pred_test)\n",
    "    print('MAE for training set is {}'.format(MAE_train))\n",
    "    print('MAE for test set is {}'.format(MAE_test))\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1702></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.2 Evaluate the model using Mean Squared Error for both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr():\n",
    "    MSE_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "    MSE_test = metrics.mean_squared_error(y_test, y_pred_test)\n",
    "    print('MSE for training set is {}'.format(MSE_train))\n",
    "    print('MSE for test set is {}'.format(MSE_test))\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1703></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.3 Evaluate the model using Root Mean Squared Error for both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def lr():\n",
    "    RMSE_train = np.sqrt( metrics.mean_squared_error(y_train, y_pred_train))\n",
    "    RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, y_pred_test))\n",
    "    print('RMSE for training set is {}'.format(RMSE_train))\n",
    "    print('RMSE for test set is {}'.format(RMSE_test))\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section1704></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.4 Evaluate the model using R-square value for both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def lr():\n",
    "    R2_train = r2_score(y_train, y_pred_train) \n",
    "    R2_test = r2_score(y_test, y_pred_test) \n",
    "    print('R2 for training set is {}'.format(R2_train))\n",
    "    print('R2 for test set is {}'.format(R2_test))\n",
    "lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with a custom input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input : \n",
    "- \"Total runs scored by team at that instance\n",
    "- \"Total wickets fallen at that instance\n",
    "- \"Total overs bowled at that instance\"\n",
    "- \"Max(runs scored by striker, runs scored by non-striker)\n",
    "- \"Min(runs scored by striker, runs scored by non-striker)\n",
    "\n",
    "Output : \n",
    "- \"Match Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with a custom input\n",
    "# ball, wicket, over, striker batman score, nonstrick batman score\n",
    "import numpy as np\n",
    "new_prediction = linreg.predict(sc.transform(np.array([[70,0,10,25,0]])))\n",
    "print(\"Prediction score:\" , new_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section18></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-sqaured is a statistic that will give some information about the goodness of fit of a model. In regression, the R-squared coefficient of determination is a statistical measure of how well the regression predictions approximate the real data points. An R-squared value of 1 indicates that the regression predictions perfectly fit the data.\n",
    "\n",
    "Below are observation for R2 using LinearRegression Model\n",
    "- R2 for training set is __0.5041672457142679__.\n",
    "- R2 for test set is __0.5090320453008903__\n",
    "\n",
    "Below are observation for R2 using RandomForestRegressor Model\n",
    "- R2 for training set is __0.895591249283709__.\n",
    "- R2 for test set is __0.668770359654934__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
